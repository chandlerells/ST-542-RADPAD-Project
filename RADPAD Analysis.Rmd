---
title: "The BEAMS Study - Baseline Evaluation And Management of Scatter radiation using RADPAD radiation absorbing drapes"
author: "Analysis completed by Sarah Pagan, Angelice Floyd, and Chandler Ellsworth"
output: pdf_document
header-includes:
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
#read in relevant packages
library(readxl)
library(tidyverse)
library(lmtest)
library(car)
library(nlme)
library(emmeans)
library(statmod)
library(tweedie)
library(glmmTMB)
#change default print option for tibbles to looking nicer when rendering to pdf
print.tbl <- function(x, ...) {
  knitr::kable(x, format = "latex", booktabs = TRUE) %>%
  kableExtra::kable_styling(latex_options = c("HOLD_position"))
}
```

```{r}
#read in Data
tib <- read_excel("RADPAD DATA Stats team 5_28_24_FINAL.xlsx", skip = 1)
```

```{r}
#select and rename relevant columns
tib <- tib %>% 
  mutate(Index = seq(1, nrow(tib), by = 1)) %>%
  select(Index, `Weight (kg)`, `Procedure  type (BPV, PDA PMI, PV Stent)`, `RADPAD Drape Used? Y/N`, 
         `Faculty`, `Tech 1`, `Resident 1`, `Resident 2`, `TEE`, `Anesthesia`, `Patient2`, `Total fluoro time (min)`, `DAP Total (Gycm2)`) %>% 
  rename("Weight" = `Weight (kg)`, "Procedure_Type" = `Procedure  type (BPV, PDA PMI, PV Stent)`, 
         "RADPAD" = `RADPAD Drape Used? Y/N`, "Tech1" = `Tech 1`, "Resident1" = `Resident 1`, 
         "Resident2" = `Resident 2`, "Patient" = `Patient2`,"Time" = `Total fluoro time (min)`, "DAP" = `DAP Total (Gycm2)`)
#convert to character type
tib[,c("Index", "Procedure_Type", "RADPAD", "Faculty", "Tech1", "Resident1", "Resident2", "TEE", "Patient")]  <- 
  lapply(tib[,c("Index", "Procedure_Type", "RADPAD", "Faculty", "Tech1", "Resident1", "Resident2", "TEE", "Patient")] , as.character)
#pivot data longer
tib_ <- tib %>%
  pivot_longer(cols = Faculty:Patient, names_to = "Lab_Personnel", values_to = "Dose")
```

# Exploratory Data Analysis

## Missing Data

First, let's explore some potential data integrity issues, which include zero values, "n/a", and "NB". A zero value means that the personnel was wearing the radiation badge but received a zero reading for dose. This may or may not be due to the personnel being far enough away from the radiation source that they were not exposed to radiation. "n/a" values mean no badge/personnel was needed. "NB" means that the personnel was there but no badge was worn.
```{r}
print(tib_ %>%
  group_by(RADPAD) %>%
  summarise(Zero = sum(Dose == 0), `n/a` = (sum(Dose == "n/a") + sum(Dose == "n /a")), NB = sum(Dose == "NB"), 
            number = sum(grepl("[1-9]", Dose))) %>%
  mutate(total = Zero + `n/a` + NB + number))

print(tib_ %>%
  group_by(Lab_Personnel) %>%
  summarise(Zero = sum(Dose == 0), `n/a` = (sum(Dose == "n/a") + sum(Dose == "n /a")), NB = sum(Dose == "NB"), 
            number = sum(grepl("[1-9]", Dose))) %>%
  mutate(total = Zero + `n/a` + NB + number))

print(tib_ %>%
  group_by(Procedure_Type) %>%
  summarise(Zero = sum(Dose == 0), `n/a` = (sum(Dose == "n/a") + sum(Dose == "n /a")), NB = sum(Dose == "NB"), 
            number = sum(grepl("[1-9]", Dose))) %>%
  mutate(total = Zero + `n/a` + NB + number))
```
There are significant data integrity issues for patient since the badge was not available during the early data collection period. Also, RADPAD does not change/affect patient dose. RADPAD is designed to lower dose to personnel (Faculty, Tech1, Resident1, Resident2, TEE, and Anesthesia). Due to these reasons, patient will be removed from the analysis.  

Resident 1 is typically closest to the x-ray beam/source and most often has a higher radiation dose as compared to resident 2. TEE is only needed in certain types of procedures, and in general, PMI does not require TEE. PDA procedure usually requires TEE. PV stents and BPVs are patient dependent on whether TEE is needed.  

Zeros will remain in the analysis until the client validates whether these should be included or not. n/a's will be removed as these personnel were not needed in the procedure. NB's will also be removed unless the client (subject matter expert) knows of common methodologies in this domain for imputing values.

```{r}
#remove relevant data
tib_ <- tib_ %>%
  filter((Dose != "n/a") & (Dose != "NB") & (Dose != "n /a") & (Lab_Personnel != "Patient")) %>%
  mutate(Dose = as.numeric(Dose), Relative_Exposure = as.numeric(Dose)/DAP)
```

## Sample Sizes

The data was provided in wide format from the client, with each observation corresponding to 1 procedure. Each lab personnel, and their corresponding dose, were provided in individual columns. 159 procedures did not use RADPAD and 49 procedures used RADPAD. The data was pivoted to long format, so that lab personnel and dose were there own columns.

With the data cleaned and pivoted to long format, lets count the number of observations we have for the relevant factors.
```{r}
#calculate sample sizes across different factors
print(tib_ %>%
  group_by(RADPAD) %>%
  summarise(Count = n()))

print(tib_ %>%
  group_by(Lab_Personnel) %>%
  summarise(Count = n()))

print(tib_ %>%
  group_by(Procedure_Type) %>%
  summarise(Count = n()))
```
As noted, there are significantly more procedures that did not use RADPAD. Of the lab personnel, TEE is worth pointing out, with over half of the observations being removed from the original data due to n/a's or NB's. Of the procedure types, PV Stent has the smallest sample size and may be challenging to analyze, especially considering the small number of PV Stent procedure that used RADPAD.

## Variation Within Each Factor

Lets look at the standard deviation within each of the factor levels. This will be a good initial check to see if the constant variance assumption in linear regression is reasonable, or if the errors are likely to be heteroskedastic. 
```{r}
#calculate standard deviation among the factor levels
print(tib_ %>%
  group_by(RADPAD) %>%
  summarise(SD = round(sd(Dose),2)))

print(tib_ %>%
  group_by(Lab_Personnel) %>%
  summarise(SD = round(sd(Dose),2)))

print(tib_ %>%
  group_by(Procedure_Type) %>%
  summarise(SD = round(sd(Dose),2)))
```
The constant variance assumption is likely to be violated considering how different the variation is across the levels of each factor.

## Factor Effects on Covariates

One of the assumptions of ANCOVA, or including a numeric covariate as a predictor along with a factor, is that the factors do not have an effect on the covariate. Lets check this by regressing each of the covariates on each of the factors and checking the corresponding p-values from an anova table. 
```{r}
df <- data.frame(
  Covariate = c(rep("DAP", 3), rep("Weight", 3), rep("Time", 3)),
  Factor = c(rep(c("RADPAD", "Lab Personnel", "Procedure Type"), 3)),
  `P-value` = 
    round(c(anova(lm(DAP ~ RADPAD, data = tib_))$`Pr(>F)`[1], 
      anova(lm(DAP ~ Lab_Personnel, data = tib_))$`Pr(>F)`[1], 
      anova(lm(DAP ~ Procedure_Type, data = tib_))$`Pr(>F)`[1], 
      anova(lm(Weight ~ RADPAD, data = tib_))$`Pr(>F)`[1],
      anova(lm(Weight ~ Lab_Personnel, data = tib_))$`Pr(>F)`[1], 
      anova(lm(Weight ~ Procedure_Type, data = tib_))$`Pr(>F)`[1], 
      anova(lm(Time ~ RADPAD, data = tib_))$`Pr(>F)`[1], 
      anova(lm(Time ~ Lab_Personnel, data = tib_))$`Pr(>F)`[1], 
      anova(lm(Time ~ Procedure_Type, data = tib_))$`Pr(>F)`[1]), 5))

knitr::kable(df, format = "latex", booktabs = TRUE) %>%
  kableExtra::kable_styling(latex_options = c("HOLD_position"))
```
Procedure type appears to be the factor that has the most significant effect on each of the covariates. This may present challenges when making conclusions from a model that includes both procedure type and the covariates. Including both may be justifable since the main factor effect of interest is RADPAD, which only has a significant effect on DAP. Lab Personnel does not appear to have an effect on any of the covariates. 

## Relative Exposure

One of the prior research papers the client provided included a similar study in human medicine as opposed to veterinary medicine. In this paper, the researchers used relative exposure (Radiation Dose/Patient DAP) as the primary response of interest as opposed to radiation dose. Using relative exposure as opposed to radiation dose accounts for interprocedural variance in patient exposure, normalizes radiation dose, and improves potential heteroskedasticity issues. Further, the primary factor of interest, RADPAD, has an effect on the primary covariate of interest, DAP, which presents challenges when including both in a model. Therefore, we will create this column in our data set and use as the new response.

Lets see if this improves the potential heteroskedasticity issue.
```{r}
#calculate standard deviation among the factor levels
print(tib_ %>%
  group_by(RADPAD) %>%
  summarise(SD = round(sd(Relative_Exposure),2)))

print(tib_ %>%
  group_by(Lab_Personnel) %>%
  summarise(SD = round(sd(Relative_Exposure),2)))

print(tib_ %>%
  group_by(Procedure_Type) %>%
  summarise(SD = round(sd(Relative_Exposure),2)))

```
Comparing the variation using relative exposure versus dose, it looks like variation across factor levels is more common using relative exposure.

## Numeric Summaries

Now that the response of interest has been selected, let's look at summary measures of RADPAD and lab personnel/procedure type across levels of RADPAD.
```{r}
#calculate numeric summaries of mean, median, and sd
print(tib_ %>%
  select(RADPAD, Relative_Exposure) %>%
  group_by(RADPAD) %>%
  summarise(
    Mean = round(mean(Relative_Exposure),2),
    Median = round(median(Relative_Exposure),2),
    SD = round(sd(Relative_Exposure),2)))

print(tib_ %>%
  select(RADPAD, Lab_Personnel, Relative_Exposure) %>%
  group_by(RADPAD, Lab_Personnel) %>%
  summarise(
    Mean = round(mean(Relative_Exposure),2),
    Median = round(median(Relative_Exposure),2),
    SD = round(sd(Relative_Exposure),2)))

print(tib_ %>%
  select(RADPAD, Procedure_Type, Relative_Exposure) %>%
  group_by(RADPAD, Procedure_Type) %>%
  summarise(
    Mean = round(mean(Relative_Exposure),2),
    Median = round(median(Relative_Exposure),2),
    SD = round(sd(Relative_Exposure),2)))
```
## Box plots

Let's further visualize the five-number summary of RADPAD and lab personnel/procedure type across levels of RADPAD.

```{r, out.width = "100%", out.height = "48%"}
#create appropriate box plots
ggplot(tib_, aes(x = RADPAD, y = Relative_Exposure, fill = RADPAD)) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0, 5)) +
  labs(title = "Boxplot of Relative Exposure by RADPAD",
       x = "RADPAD",
       y = "Relative Exposure") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

ggplot(tib_, aes(x = Lab_Personnel, y = Relative_Exposure, fill = RADPAD)) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0, 7)) +
  labs(title = "Boxplot of Relative Exposure by Lab Personnel",
       x = "Lab Personnel",
       y = "Relative Exposure") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

ggplot(tib_, aes(x = Procedure_Type, y = Relative_Exposure, fill = RADPAD)) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0, 7)) +
  labs(title = "Boxplot of Relative Exposure by Procedure Type",
       x = "Procedure Type",
       y = "Relative Exposure") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

```

The box plots had to be zoomed in on a specific range of relative exposure because there are significant outliers in the data. Since these could not be captured from the box plots, let's look at tables that show the .9 quantile and max value of RADPAD and lab personnel/procedure type across levels of RADPAD.
```{r}
#calculate .9 quantile and max value
print(tib_ %>%
  select(RADPAD, Relative_Exposure) %>%
  group_by(RADPAD) %>%
  summarise(
    Q90 = round(quantile(Relative_Exposure, 0.9),2),
    Max = round(max(Relative_Exposure),2)))

print(tib_ %>%
  select(RADPAD, Lab_Personnel, Relative_Exposure) %>%
  group_by(RADPAD, Lab_Personnel) %>%
  summarise(
    Q90 = round(quantile(Relative_Exposure, 0.9),2),
    Max = round(max(Relative_Exposure),2)))

print(tib_ %>%
  select(RADPAD, Procedure_Type, Relative_Exposure) %>%
  group_by(RADPAD, Procedure_Type) %>%
  summarise(
    Q90 = round(quantile(Relative_Exposure, 0.9),2),
    Max = round(max(Relative_Exposure),2)))
```
The difference in just the .9 quantile value and max value are significant for many of the factor levels across RADPDAD, which may indicates significant outliers in the data. 

## Histograms

Since many models make the assumption errors, and therefore the response, are normally distributed, let's look at density plots of relative exposure both with and without some common transformations. Within each plot, a smooth normal density curve will be overlaid to see how it compares to the observed data.
```{r}
#set up a 2x2 plotting space
par(mfrow = c(2, 2))

#create histograms and overlay normal density curves
#no transformations
hist(tib_$Relative_Exposure, breaks = 20, freq = FALSE, col = 'skyblue', main = 'No Transform', xlab = 'Relative Exposure')
x <- seq(min(tib_$Relative_Exposure), max(tib_$Relative_Exposure), length = 100)
y <- dnorm(x, mean = mean(tib_$Relative_Exposure), sd = sd(tib_$Relative_Exposure))
lines(x, y, col = 'darkgreen', lwd = 2)

#create function to apply the optimal lambda to transform the response variable using Box-Cox
box_transform <- function(response, lambda) {
  if (lambda == 0) {
    response <- log(response)
  } else {
    response <- (response^lambda - 1) / lambda
  }
  return(response)
}

#perform Box-Cox transformation on the response variable
bc <- MASS::boxcox(lm((Relative_Exposure + 1) ~ RADPAD*Procedure_Type*Lab_Personnel + Weight + Time, data = tib_), plotit = FALSE)
lambda_optimal <- bc$x[which.max(bc$y)]
check_response <- box_transform(tib_$Relative_Exposure + 1, lambda_optimal)

#Box-Cox transformation
hist(check_response, breaks = 20, freq = FALSE, col = 'skyblue', main = 'BoxCox Transform', xlab = 'Relative Exposure')
x <- seq(min(check_response), max(check_response), length = 100)
y <- dnorm(x, mean = mean(check_response), sd = sd(check_response))
lines(x, y, col = 'darkgreen', lwd = 2)

#log transformation
hist(log(tib_$Relative_Exposure + 1), breaks = 20, freq = FALSE, col = 'skyblue', main = 'Log Transform', xlab = 'Relative Exposure')
x <- seq(min(log(tib_$Relative_Exposure + 1)), max(log(tib_$Relative_Exposure + 1)), length = 100)
y <- dnorm(x, mean = mean(log(tib_$Relative_Exposure + 1)), sd = sd(log(tib_$Relative_Exposure + 1)))
lines(x, y, col = 'darkgreen', lwd = 2)

#square root transformation
hist(sqrt(tib_$Relative_Exposure), breaks = 20, freq = FALSE, col = 'skyblue', main = 'Square Root Transform', xlab = 'Relative Exposure')
x <- seq(min(sqrt(tib_$Relative_Exposure)), max(sqrt(tib_$Relative_Exposure)), length = 100)
y <- dnorm(x, mean = mean(sqrt(tib_$Relative_Exposure)), sd = sd(sqrt(tib_$Relative_Exposure)))
lines(x, y, col = 'darkgreen', lwd = 2)

#reset plotting parameters to default
par(mfrow = c(1, 1))
```
None of the most common transformations significantly make the response look normal. However, the Box-Cox transformation will be used when a transformation is needed, as it looks better and improves the homoscedasticity assumption of the errors compared to the other transformations.

## Scatter Plots

Many statistical models also generally make the assumption the relationship between the response and the combination of factors and covariates is linear. While scatter plots of the response against each covariate, possibly stratified by levels of the factors, could be used to visually assess linearity, the assumption does not necessarily imply that the response is linear in terms of subsets of the factors and covariates individually, but rather in terms of the overall model. For now, let's look at scatter plots of the response against each covariate to assess a linear relationship. Later, during the model fitting process, if residual plots exhibit some sort of pattern or behavior, we will further investigate if the linearity assumption holds for that particular model. We can do this by looking at partial regression or added variable plots, although these can be difficult to interpret with factor variables.
```{r}
#set up a 2x2 plotting space
par(mfrow = c(1, 2))
#fit linear model to plot on scatter plot
fit <- lm(Relative_Exposure ~ Weight, data = tib_)
#create scatter plot
plot(tib_$Weight, tib_$Relative_Exposure,
     main = "Scatter Plot of Weight vs Relative Exposure",
     xlab = "Weight (kg)",
     ylab = "Relative Exposure",
     ylim = c(0,30),
     pch = 1,  
     col = "black",  
     frame = FALSE,
     cex.main = 0.8, 
     cex.lab = 0.8,
     cex.axis = 0.8) 
#add correlation text value to the plot
text(max(tib_$Weight), 30, 
     label = paste("Correlation =", round(cor(tib_$Weight, tib_$Relative_Exposure),3)),
     adj = c(1, 1),
     font = 2,
     cex = 0.7)
#add fitted regression line
abline(fit, col = "red", lwd = 1)
#fit linear model to plot on scatter plot
fit2 <- lm(Relative_Exposure ~ Time, data = tib_)
#create scatter plot
plot(tib_$Time, tib_$Relative_Exposure,
     main = "Scatter Plot of Time vs Relative Exposure",
     xlab = "Time (min)",
     ylab = "Relative Exposure",
     ylim = c(0,30),
     pch = 1, 
     col = "black",  
     frame = FALSE,
     cex.main = 0.8, 
     cex.lab = 0.8,
     cex.axis = 0.8)
#add correlation text value to the plot
text(max(tib_$Time), 30, 
     label = paste("Correlation =", round(cor(tib_$Time, tib_$Relative_Exposure),3)),
     adj = c(1, 1),
     font = 2,
     cex = 0.7)
#add fitted regression line
abline(fit2, col = "red", lwd = 1)
```
From the plots and correlation values, there does not appear to be a significant linear relationship between weight and relative exposure, as well as time and relative exposure. Note also that some of the values were cutoff, as a few extreme relative exposure values distorted the scatter plots.

## Interaction Plots

Lastly, let's look at relevant two-way and three-way interaction plots to explore and understand interactions between factors. This will allow us to visually investigate if the effect of one factor on relative exposure depends on the level of another factor.
```{r, out.width = "55%", out.height = "50%"}
#create plot margins
par(mar = c(5, 4, 4, 5), xpd = TRUE)
#create two-way interaction plot between RADPAD and procedure type
interaction.plot(
  x.factor = tib_$Procedure_Type,
  trace.factor = tib_$RADPAD,
  response = tib_$Relative_Exposure, 
  legend = FALSE,
  col = c("red", "blue"), 
  lty = 1,
  pch = 20,
  type = "b",
  xlab = "Procedure Type", 
  ylab = "Mean Relative Exposure",
  main = "Interaction Plot of RADPAD and Procedure Type"
)
#add legend to interaction plot
legend("topright", inset = c(-.2, 0), legend = unique(tib_$RADPAD), 
       col = c("red", "blue"), 
       pch = 20, 
       lty = 1, 
       box.lty = 1,
       title = "RADPAD")
#make x-axis ticks smaller so they are all shown
par(cex.axis = .9)
#create two-way interaction plot between RADPAD and lab personnel
interaction.plot(
  x.factor = tib_$Lab_Personnel,
  trace.factor = tib_$RADPAD,
  response = tib_$Relative_Exposure, 
  legend = FALSE,
  col = c("red", "blue"), 
  lty = 1,
  pch = 20,
  type = "b",
  xlab = "Lab Personnel", 
  ylab = "Mean Relative Exposure",
  main = "Interaction Plot of RADPAD and Lab Personnel"
)
#add legend to interaction plot
legend("topright", inset = c(-.2, 0), legend = unique(tib_$RADPAD), 
       col = c("red", "blue"), 
       pch = 20, 
       lty = 1, 
       box.lty = 1,
       title = "RADPAD")
```
```{r}
#create data frame of means across each combination of the three factors
mean_data <- aggregate(Relative_Exposure ~ RADPAD + Lab_Personnel + Procedure_Type, data = tib_, FUN = mean)
#create three-way interaction plot
ggplot(mean_data, aes(x = Lab_Personnel, y = Relative_Exposure, color = RADPAD)) +
  geom_point(size = 2) +
  geom_line(aes(group = interaction(RADPAD, Procedure_Type)), size = 1) +
  facet_wrap(~ Procedure_Type, scales = "free") +
  labs(x = "Lab Personnel", y = "Mean Relative Exposure", color = "RADPAD") +
  theme_minimal() +
  theme(legend.position = "right",
        axis.text.x = element_text(size = 7)) +
  ggtitle("Three-Way Interaction Plot Between RADPAD, Lab Personnel, & Procedure Type") + 
  theme(axis.text.x = element_text(angle = 35, hjust = .8))
```

From the two-way interaction plots, the lines indicated by RADPAD level do not cross and appear somewhat parallel. This may indicate that it is plausible the effect of RADPAD is constant across levels of procedure type or levels of lab personnel. The three-way interaction plot looks fairly similar to the two-way interaction plot between RADPAD and lab personnel, with differences in the effect of RADPAD in the PMI procedure for TEE, as well as the PV Stent procedure for resident 2 and TEE.

# Model Fitting

In this section, let's begin fitting models, analyzing the output, and checking assumptions.

## ANCOVA & ANOVA Using Full Data Set

To start, let's fit a model that includes all factors, their interaction, all covariates, original response, and no transformations.
$$
y_{ijkl} = \mu + \alpha_{i} + \beta_{j} + \gamma_{k} + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \lambda_{1}x_{ijkl1} + \lambda_{2}x_{ijkl2} + \lambda_{3}x_{ijkl3} + e_{ijkl} 
$$
$$
\text{where} \ e_{ijkl} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{relative exposure}, \ x_{1} = \text{weight}, \ x_{2} = \text{time}, \  x_{3} = \text{DAP}
$$
$$
\text{for} \ i = 1,2 \ (\text{RADPAD}), \ \ j = 1,2,3,4,5,6 \ (\text{lab personnel}), \ k = 1,2,3,4 \ (\text{procedure type})
$$

```{r, fig.show = "hold", out.width = "100%", out.height = "46%"}
#fit linear regression model
lm.fit <- lm(Dose ~ RADPAD*Lab_Personnel*Procedure_Type + Weight + Time + DAP, 
             data = tib_)
#look at anova table
anova(lm.fit)
#plot residuals
par(mar = c(4, 4, 1.5, 1))
plot(lm.fit, which = c(1,2), sub = "")
```

The residual and QQ plots show significant violations of model assumptions.

To attempt to improve model assumptions, let's fit a model transforming the new response, relative exposure, with a Box-Cox transformation. All factors and their interactions will be included, along with the covariates weight and time.
$$
y_{ijkl} = \mu + \alpha_{i} + \beta_{j} + \gamma_{k} + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \lambda_{1}x_{ijkl1} + \lambda_{2}x_{ijkl2} + e_{ijkl} 
$$
$$
\text{where} \ e_{ijkl} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure)}, \ x_{1} = \text{weight}, \ x_{2} = \text{time}
$$
$$
\text{for} \ i = 1,2 \ (\text{RADPAD}), \ \ j = 1,2,3,4,5,6 \ (\text{lab personnel}), \ k = 1,2,3,4 \ (\text{procedure type})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "46%"}
#fit linear regression model
lm.fit <- lm(box_transform(tib_$Relative_Exposure + 1, lambda_optimal) ~ RADPAD*Lab_Personnel*Procedure_Type + Weight + Time, 
             data = tib_)
#look at anova table
anova(lm.fit)
#plot residuals
par(mar = c(4, 4, 1.5, 1))
plot(lm.fit, which = c(1,2), sub = "")
```

While model assumptions improve, there are still significant violations of constant variance and normality.

Let's slowly walk through each of the factors, adding one factor at a time, to see where the model violations start to appear.
$$
y_{ij} = \mu + \alpha_{i} + e_{ij}
$$
$$
\text{where} \ e_{ij} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure)}
$$
$$
\text{for} \ i = 1,2 \ (\text{RADPAD})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "30%"}
#perform Box-Cox transformation on the response variable
bc <- MASS::boxcox(lm((Relative_Exposure + 1) ~ RADPAD, data = tib_), plotit = FALSE)
lambda_optimal <- bc$x[which.max(bc$y)]
#fit model and look at residual plot
par(mar = c(4, 4, 1.5, 1))
plot(lm(box_transform(Relative_Exposure + 1, lambda_optimal) ~ RADPAD, data = tib_), 
     which = 1, sub = "")
```

$$
y_{ij} = \mu + \beta_{i} + e_{ij}
$$
$$
\text{where} \ e_{ij} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure)}
$$
$$
\text{for} \ i = 1,2,3,4,5,6 \ (\text{lab personnel})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "30%"}
#perform Box-Cox transformation on the response variable
bc <- MASS::boxcox(lm((Relative_Exposure + 1) ~ Lab_Personnel, data = tib_), plotit = FALSE)
lambda_optimal <- bc$x[which.max(bc$y)]
#fit model and look at residual plot
par(mar = c(4, 4, 1.5, 1))
plot(lm(box_transform(Relative_Exposure + 1, lambda_optimal) ~ Lab_Personnel, data = tib_), 
     which = 1, sub = "")
```

$$
y_{ij} = \mu + \gamma_{i} + e_{ij}
$$
$$
\text{where} \ e_{ij} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure)}
$$
$$
\text{for} \ i = 1,2,3,4 \ (\text{procedure type})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "30%"}
#perform Box-Cox transformation on the response variable
bc <- MASS::boxcox(lm((Relative_Exposure + 1) ~ Procedure_Type, data = tib_), plotit = FALSE)
lambda_optimal <- bc$x[which.max(bc$y)]
#fit model and look at residual plot
par(mar = c(4, 4, 1.5, 1))
plot(lm(box_transform(Relative_Exposure + 1, lambda_optimal) ~ Procedure_Type, data = tib_), 
     which = 1, sub = "")
```

$$
y_{ijk} = \mu + \alpha_{i} + \beta_{j} + (\alpha\beta)_{ij} + e_{ijk}
$$
$$
\text{where} \ e_{ijk} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure)}
$$
$$
\text{for} \ i = 1,2 \ (\text{RADPAD}), \ j = 1,2,3,4,5,6 \ (\text{lab personnel})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "30%"}
#perform Box-Cox transformation on the response variable
bc <- MASS::boxcox(lm((Relative_Exposure + 1) ~ RADPAD*Lab_Personnel, data = tib_), plotit = FALSE)
lambda_optimal <- bc$x[which.max(bc$y)]
#fit model and look at residual plot
par(mar = c(4, 4, 1.5, 1))
plot(lm(box_transform(Relative_Exposure + 1, lambda_optimal) ~ RADPAD*Lab_Personnel, data = tib_), 
     which = 1, sub = "")
```

$$
y_{ijk} = \mu + \alpha_{i} + \gamma_{j} + (\alpha\gamma)_{ij} + e_{ijk}
$$
$$
\text{where} \ e_{ijk} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure)}
$$
$$
\text{for} \ i = 1,2 \ (\text{RADPAD}), \ j = 1,2,3,4 \ (\text{procedure type})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "30%"}
#perform Box-Cox transformation on the response variable
bc <- MASS::boxcox(lm((Relative_Exposure + 1) ~ RADPAD*Procedure_Type, data = tib_), plotit = FALSE)
lambda_optimal <- bc$x[which.max(bc$y)]
#fit model and look at residual plot
par(mar = c(4, 4, 1.5, 1))
plot(lm(box_transform(Relative_Exposure + 1, lambda_optimal) ~ RADPAD*Procedure_Type, data = tib_), 
     which = 1, sub = "")
```

$$
y_{ijkl} = \mu + \alpha_{i} + \beta_{j} + \gamma_{k} + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + e_{ijkl} 
$$
$$
\text{where} \ e_{ijkl} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure)}
$$
$$
\text{for} \ i = 1,2 \ (\text{RADPAD}), \ \ j = 1,2,3,4,5,6 \ (\text{lab personnel}), \ k = 1,2,3,4 \ (\text{procedure type})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "30%"}
#perform Box-Cox transformation on the response variable
bc <- MASS::boxcox(lm((Relative_Exposure + 1) ~ RADPAD*Procedure_Type*Lab_Personnel, data = tib_), plotit = FALSE)
lambda_optimal <- bc$x[which.max(bc$y)]
#fit model and look at residual plot
par(mar = c(4, 4, 1.5, 1))
plot(lm(box_transform(Relative_Exposure + 1, lambda_optimal) ~ RADPAD*Procedure_Type*Lab_Personnel, data = tib_), 
     which = 1, sub = "")
```

After trying to diagnose where the assumption violations start to occur, it appears in almost all cases the normality and constant variance assumptions will be violated, especially when lab personnel is included in the model. This makes sense because from the EDA, it was apparent the response, or any common transformation on the response, was not normal. Also there were significant differences in variation across factor levels.

If normality of residuals appears valid, generalized least squares can be used to relax error assumptions of independence and constant variance. Models where assumption of normality of residuals is clearly violated using a Box-Cox transformation include:  

- All three factors, their interactions, and covariates, weight and time  
- All three factors, no interactions, and covariates, weight and time  
- All three factors and their interactions, no covariates  
- All three factors, no interactions, no covariates  
- All three factors and their interactions, no covariates, data filtered to remove TEE and tech1  
- All three factors and their interactions, no covariates, data filtered to remove TEE, tech1, and Anesthesia   
- All three factors and their interactions, no covariates, data filtered to remove TEE and tech1 and procedure type pv stent  
- RADPAD and lab personnel, their interaction, covariates weight and time, procedure type filtered on PDA  

A few important reasons why the normality and constant variance assumption of errors could be violated:  

1. There are a significant amount of zeros in the data and the data is heavily skewed towards zero.  
2. We are missing some other major factor or covariate, such as distance from the radiation source.  
3. Small sample sizes for a few of the procedures and lab personnel.  
4. Many of the lab personnel aside from resident 1 have questionable data. This is likely due to the distance of certain personnel within a fixed procedure being highly variable and not controlled for. Further, certain personnel are able to see real time their radiation exposure and adjust their position accordingly.  
5. Not a randomized controlled experiment.  

To conduct proper inference using a model with valid assumptions, we will likely need to do linear regression on a subset of the data, or relax the assumptions of normality, constant variance, etc., by using a general linear model and modeling the errors with some form of a zero inflated distribution, or by using generalized least squares. 

### Filter Lab Personnel for Resident 1

First, since analyzing the effect of RADPAD on radiation exposure for resident 1 is of primary interest and resident 1 does not have any zero values, let's filter the data set for just resident 1 and see if this improves model assumptions. Note that procedure type has a significant effect on weight and time.
$$
y_{ijk} = \mu + \alpha_{i} + \beta_{j} + (\alpha\beta)_{ij} + \lambda_{1}x_{ijkl1} + \lambda_{2}x_{ijkl2} + e_{ijk} 
$$
$$
\text{where} \ e_{ijk} \overset{IID}{\sim} N(0,\sigma^2), \ y = \text{Box-Cox(relative exposure for resident1)}, \ x_{1} = \text{weight}, \ x_{2} = \text{time}
$$
$$
\text{for} \ i = 1,2 \ (\text{RADPAD}), \ \ j = 1,2,3,4 \ (\text{procedure type})
$$
```{r, fig.show = "hold", out.width = "100%", out.height = "46%"}
#filter data for only resident 1
res1 <- tib_ %>%
  filter(Lab_Personnel == "Resident1") %>%
  select(Relative_Exposure, RADPAD, Procedure_Type, Weight, Time)
# Perform Box-Cox transformation on the response variable y
bc <- MASS::boxcox(lm(Relative_Exposure ~  RADPAD * Procedure_Type + Weight + Time, 
                      data = res1), plotit = FALSE)
# Extract the optimal lambda
lambda_optimal <- bc$x[which.max(bc$y)]
#fit model
lm.fit <- lm(box_transform(Relative_Exposure, lambda_optimal) ~ RADPAD * Procedure_Type + Weight + Time, 
             data = res1)
#look at residual and qq plot
par(mar = c(4, 4, 1.5, 1))
plot(lm.fit, which = c(1,2), sub = "")
```

Overall, the residual and QQ plots look significantly better. Let's use formal tests to check these as well.  
We will use:  

- Shapiro Test to test for normality  
- Durbin-Watson Test to test for correlation  
- Breusch-Pagan Test to test for constant variance  

```{r}
#conduct Shapiro Test
shapiro.test(rstandard(lm.fit))
#conduct Durbin-Watson Test
dwtest(lm(box_transform(Relative_Exposure, lambda_optimal) ~ RADPAD * Procedure_Type + Weight + Time, 
          data = res1))
#conduct Breusch-Pagan Test
bptest(lm.fit, studentize = TRUE)
```
All of the tests came back insignificant except the Breusch-Pagan test. Since this test is significant, we reject the null using a significance level of 0.05 and conclude there is heteroskedasticity in the errors. Let's attempt to correct for this by assuming unequal error variance using generalized least squares. We can compare unequal error variance between only RADPAD levels, only procedure type levels, and combinations of RADPAD and procedure type levels using AIC. We can use AIC to compare models since the form of how the factors and covariates are included in the model is the same. 
```{r}
#create appropriate Box-Cox transformation of response to use in gls
box <- box_transform(res1$Relative_Exposure, lambda_optimal)
#ordinary least squares
gls.fit <- gls(box ~ RADPAD * Procedure_Type + Weight + Time, 
    data = res1)
#unequal variance between RADPAD levels
gls.fit2 <- gls(box ~ RADPAD * Procedure_Type + Weight + Time, 
    data = res1,
    weights = varIdent(form = ~ 1 | RADPAD))
#unequal variance between procedure type levels
gls.fit3 <- gls(box ~ RADPAD * Procedure_Type + Weight + Time, 
    data = res1,
    weights = varIdent(form = ~ 1 | Procedure_Type))
#unequal variance between combinations of RADPAD and procedure type levels
gls.fit4 <- gls(box ~ RADPAD * Procedure_Type + Weight + Time, 
    data = res1,
    weights = varIdent(form = ~ 1 | RADPAD*Procedure_Type))
#output AIC for each of the models
df <- AIC(gls.fit, gls.fit2, gls.fit3, gls.fit4)
#change row names of data frame
rownames(df) <- c("Equal Variance", "RADPAD Unequal Variance", "PType Unequal Variance", "RADPAD*PType Unequal Variance")
#show results
knitr::kable(df, format = "latex", booktabs = TRUE) %>%
  kableExtra::kable_styling(latex_options = c("HOLD_position"))
#compare ols and unequal error variance for RADPAD levels with anova
df <- anova(gls.fit, gls.fit2)
#change row names of data frame
rownames(df) <- c("Equal Variance", "RADPAD Unequal Variance")
#show results
df
```
It appears the model with the lowest AIC is the model that assumes unequal variance between RADPAD levels. This model also appears to improve the fit since the likelihood ratio test is significant when comparing the model which assumes unequal variance in RADPAD groups to the model which assumes equal variance between groups.

Let's analyze the residual and QQ plots for the new model which assumes unequal variance between RADPAD groups.
```{r, fig.show = "hold", out.width = "100%", out.height = "46%"}
#get the residuals (standardized)
residual <- residuals(gls.fit2, type = 'pearson')
#get the fitted values
fitted_values <- fitted(gls.fit2)
#plot residuals vs fitted
plot(fitted_values, residual, xlab = "Fitted values", ylab = "Pearson residuals", main = "Residuals vs Fitted", pch = 1, col = "dodgerblue")
abline(h=0)
#normal QQ plot
qqnorm(residual, pch = 1, col = "dodgerblue")
abline(0,1, lwd=2)
```

From the plots, it appears the normality assumption is valid and there does not need to be any more adjustment to the variance. Let's formalize by looking at the White test again. Testing for heteroskedasticity from a gls() object is challenging because most of the common tests (like the Breusch-Pagan test) are designed for lm() objects. However, we can still test for heteroskedasticity using the White test, which is adaptable to the residuals from a gls() object. The White test is a more general test for heteroskedasticity.
```{r}
white_test <- data.frame(
  residuals = residual,
  fitted_values = fitted_values)
#conduct White Test
bptest(I(residuals^2) ~ fitted_values + I(fitted_values^2), data = white_test)
```
The p-value is very high, therefore we fail to reject the null.

Let's look at the anova table for the new model.
```{r}
#output anova table
anova(gls.fit2)
```
RADPAD, procedure type, and weight are highly significant using a significance level of 0.05. Time and the interaction between RADPAD and procedure type are not significant using a significance level of 0.05.

Let's analyze the main effect of RADPAD averaging over procedure type, holding constant weight and time at their average respective values, as well as simple effects of RADPAD within each procedure, holding constant weight and time at their average respective values. 
```{r}
# Compute contrasts
emm1 <- emmeans(gls.fit2, ~ RADPAD, mode = "df.error")
emm2 <- emmeans(gls.fit2, ~ RADPAD | Procedure_Type, mode = "df.error")
c1 <- contrast(emm1, method = "pairwise")
c2 <- contrast(emm2, method = "pairwise")
#print summaries
knitr::kable(as.data.frame(summary(c1, infer = c(TRUE, TRUE))), format = "latex", booktabs = TRUE) %>%
  kableExtra::kable_styling(latex_options = c("HOLD_position"))
knitr::kable(as.data.frame(summary(c2, infer = c(TRUE, TRUE))), format = "latex", booktabs = TRUE) %>%
  kableExtra::kable_styling(latex_options = c("HOLD_position"))
```

Note this approach only works for resident 1. The model assumptions are still invalid using this approach for other important personnel such as resident 2, faculty, and anesthesia.

## Generalized Linear Model


### Tweedie Distribution
Let's take a look again at the distribution of the relative exposure, this time let's overlay a smooth gamma distribution instead of a normal.
```{r, fig.show = "hold", out.width = "100%", out.height = "35%"}
#no transformations
hist(tib_$Relative_Exposure + 1, breaks = 20, freq = FALSE, col = 'skyblue', main = 'No Transform', xlab = 'Relative Exposure')
#fit gamma distribution
gamma.fit <- MASS::fitdistr(tib_$Relative_Exposure + 1, densfun = "gamma")
#estimate shape and rate paremeter
shape <- gamma.fit$estimate["shape"]
rate <- gamma.fit$estimate["rate"]
#overlay smooth gamma desnity
x <- seq(min(tib_$Relative_Exposure + 1), max(tib_$Relative_Exposure + 1), length = 100)
gamma_density <- dgamma(x, shape = shape, rate = rate)
lines(x, gamma_density, col = "blue", lwd = 2)
```

Clearly this distribution does not look normal. The majority of the values are at or very close to 0. The gamma distribution looks more appropriate, but unfortunately, a gamma distribution only has positive non-zero values. Because of this, let's fit a generalized linear model using the Tweedie distribution family. The Tweedie distribution is more appropriate because it takes on non-negative values. The model form will include two factor interactions between RADPAD and procedure type and RADPAD and lab personnel, as well as both covariates weight and time.
```{r, fig.show = "hold", out.width = "100%", out.height = "46%"}
#fit a GLM with tweedie family
glm.fit <- tweedie_model <- glm(Relative_Exposure ~ RADPAD*Procedure_Type + RADPAD*Lab_Personnel + Weight + Time, 
                     family = statmod::tweedie(var.power = 2, link.power = 0), 
                     data = tib_)
#plot output
plot(glm.fit, which=c(1,2),  sub = "")
#look at estimates
summary(glm.fit)
```

### Zero-Inflated Gamma Distribution
Let's also look at modeling a zero-inflated gamma distribution. This allows for modeling the zeros (zero inflated part) separate from the positive continuous values (here gamma). The model form will include two factor interactions between RADPAD and procedure type and RADPAD and lab personnel, as well as both covariates weight and time. The zero values will be modeling using an intercept and factoring in lab personnel.
```{r}
#fit zero-inflated gamma model
zig.fit <- glmmTMB(Relative_Exposure ~ RADPAD*Procedure_Type + RADPAD*Lab_Personnel + Weight + Time,
                  ziformula = ~ Lab_Personnel,
                  family = ziGamma(link = "log"), 
                  data = tib_)
# Summary of the model
summary(zig.fit)
```
Some of the key assumptions of this model are: 

- There are more zeros in the data than would be expected from a standard gamma distribution.  
- The positive, non-zero part of the data follows a gamma distribution.
- Observations are independent of each other.  
- Both the zero-inflation model and the gamma model are correctly specified. This includes the correct functional form and inclusion of relevant factors/covariates.

Let's check some of these assumptions using plots.
```{r, fig.show = "hold", out.width = "100%", out.height = "46%"}
#calculate the observed proportion of zeros
observed_zeros <- mean(tib_$Relative_Exposure == 0)
#calculate the predicted proportion of zeros
predicted_zeros <- mean(predict(zig.fit, type = "zprob"))
#print the observed and predicted proportions
list("Observed zeros" = observed_zeros, "Predicted zeros" = predicted_zeros)

#plot the residuals
plot(DHARMa:: simulateResiduals(fittedModel = zig.fit))

#residuals vs. procedure plot
DHARMa::plotResiduals(DHARMa:: simulateResiduals(fittedModel = zig.fit), form = tib_$Index)

#extract positive values
positive_values <- tib_$Relative_Exposure[tib_$Relative_Exposure > 0]
#fit a gamma distribution to the positive values
gamma_fit <- fitdistrplus::fitdist(positive_values, "gamma")
#Q-Q plot for the gamma distribution
fitdistrplus::qqcomp(list(gamma_fit))
```

Residual diagnostics show significant violations indicating model misfit, over dispersion and outliers present.

Attempts that were made that did not help violated assumptions from plots: 

- Remove interactions  
- Adding more factors to zero inflated component  
- Removing covariates  

Two other points to note:

- Unable able to add a random effect in glmmTMB for procedure index  
- Tweedie distribution on positive continuous component has significant run-time and would not plot  

Let's try and use the zero-inflated gamma, but this time filtered specifically on faculty and resident 2. Let's start with these two examples to see if filtering on the data improves the assumptions. The zero-inflated component will account for an intercept and the factor procedure type. The model form with have RADPAD and procedure type, their interaction, and both covariates weight and time.
```{r, fig.show = "hold", out.width = "100%", out.height = "46%"}
#fit zero-inflated gamma model
zig.fit2 <- glmmTMB(Relative_Exposure ~ RADPAD*Procedure_Type + Weight + Time,
                  ziformula = ~ Procedure_Type,
                  family = ziGamma(link = "log"), 
                  data = tib_ %>% filter(Lab_Personnel == "Faculty"))
#fit zero-inflated gamma model
zig.fit3 <- glmmTMB(Relative_Exposure ~ RADPAD*Procedure_Type + Weight + Time,
                  ziformula = ~ Procedure_Type,
                  family = ziGamma(link = "log"), 
                  data = tib_ %>% filter(Lab_Personnel == "Resident2"))
#diagnostic plots
plot(DHARMa:: simulateResiduals(fittedModel = zig.fit2))
plot(DHARMa:: simulateResiduals(fittedModel = zig.fit3))

```

Diagnostic plots look much better, but dispersion tests are still significant.




















